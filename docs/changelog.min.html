<!doctype html><html lang=en><meta charset=UTF-8><meta content="width=device-width,initial-scale=1.0" name=viewport><link crossorigin href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css integrity=sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH rel=stylesheet><link onload="this.onload=null;this.rel='stylesheet'" as=style href=./css/bootstrap-icons.min.mincss3k.css rel=preload><noscript><link href=./css/bootstrap-icons.min.mincss3k.css rel=stylesheet></noscript><script crossorigin integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz rel=preload src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js></script><script defer src=./js/ui.min.js></script><script src=./js/codegen.min.js></script><script src=./js/pgtuner.min.js></script><meta content="PGTuner: The :project:`pgtuner` (or PostgreSQL: DBA & Tuner) is a SQL/Python-based project designed to manage and optimize kernel parameters and database settings, focusing on TCP networking (connection management, retries, timeouts, and **buffering**), memory management (swappiness, caching), and IO optimization; whilst maintaining high performance, stability, and concurrency for various system configurations. The tuning is inspired by many successful world-wide clusters (Notion, Cloudflare, ...) from OS part, and many DBA's experts at PostgreSQL community (OnGres, Cybertec PostgreSQL, PostgreSQL thread issues, GitLab, ...)." name=description><title>PGTuner - Automatic PostgreSQL Tuning Tool</title><link href=./resource/favicon.ico rel=icon><header class=py-3 style=background:linear-gradient(#f207b8,#f564e9)><div class="container d-flex justify-content-between align-items-center"><div class="d-flex align-items-center"><img alt="PGTuner Logo" class=me-2 fetchpriority=high height=60 src=./resource/icon.min.png width=60><div><h1 class="h4 mb-0 text-white">PGTuner v0.1.5</h1><small class=text-light>Extensive PostgreSQL optimization for modern use-case</small></div></div><nav class="d-flex align-items-center"><ul class="nav me-3"><li class=nav-item><a class="nav-link text-white fw-bold" href=./tuner.min.html>Home</a><li class=nav-item><a class="nav-link text-white fw-bold" href=./changelog.min.html> Changelog </a><li class=nav-item><a class="nav-link text-white fw-bold" href=https://github.com/IchiruTake/pgtuner target=_blank> <i class="bi bi-github mx-1"></i> Contribute </a></ul></nav></div></header><body><section class="container my-5"><h2 class="text-center my-3">Changelog</h2><div class="accordion accordion-flush" id=changelogAccordion><div class=accordion-item><h2 class=accordion-header id=hdr000200><button class="accordion-button collapsed" aria-controls=collapse000200 aria-expanded=true data-bs-target=#collapse000200 data-bs-toggle=collapse type=button>v0.x.x (x) - Date: Unknown</button></h2><div class="accordion-collapse collapse" aria-labelledby=hdr000200 data-bs-parent=#changelogAccordion id=collapse000200><div class=accordion-body><ul><li>Cleanup development and legacy code<li>TODO: Add automatic tests to detect error<li>TODO: More refined documentation with icon symbol of importance<li>TODO: Rewrite application as Javascript to support global user (if necessary)</ul></div></div></div><div class=accordion-item><h2 class=accordion-header id=hdr000105><button aria-controls=collapse000105 aria-expanded=true class=accordion-button data-bs-target=#collapse000105 data-bs-toggle=collapse type=button>v0.1.5 - Expected Date: May 12th 2025</button></h2><div class="accordion-collapse collapse show" aria-labelledby=hdr000105 data-bs-parent=#changelogAccordion id=collapse000105><div class=accordion-body><ul><li>Generic: The codebase has been refactored with the decision of hosting dual-backend in the same repository. Multiple functions has been revised to reduce performance noise, and multiple optimizations has been added to the codebase <ul><li>APP: We has completed the transition from Python and Javascript, with the decision of hosting dual-backend in the same repository.<li>APP: Adding the support to PostgreSQL 18</ul><li>Input Changes <ul><li>PY_BKE: Now user has to self-supplied the configuration they wanted rather than naively use the default input. See `./pgtuner_cli.py` for usage<li>CONF: Introduce the parameter `cpu_to_connection_scale_ratio` with default to 4 (range from [2.5, 10]) to support the variety of scaling the number of connections in the general optimization phase.<li>CONF: Increase the parameter `memory_connection_to_dedicated_os_ratio` from 0.3 to 0.7<li>CONF: Change the default parameter of `hash_mem_usage_level` is changed from -6 to -5. If hash_mem_multiplier is 2.0, the working memory usage per connection for one arbitrary operation is increased from 1.1196 to 1.1417<li>CONF: Revert the upper bound parameter of `wal_segment_size` to 2 GiB instead of 128 MiB (scale from 3 to 7)<li>CONF: Change the default parameter of `min_wal_size_ratio` from 0.03 to 0.05<li>CONF: Change the default parameter of `mem_pool_tuning_ratio` from 0.6 to 0.4<li>CONF: Remove all `*_profile` parameters except the `workload_profile` parameter.<li>CONF: The supported PostgreSQL version is using the integer instead of string (including the term 'latest').<li>CONF: Remove parameters of the OS and DB Log disk<li>CONF: Enumeration the backup tool from string to :enum:`PG_BACKUP_TOOL`<li>CONF: The only supported operating system is 'linux', 'windows', 'macos', 'containerd', and 'PaaS'<li>CONF: Remove the workload of SOLTP, LOG, DW in :enum:`PG_WORKLOAD`</ul><li>Algorithm Changes <ul><li>PY_BKE: Disable SYSCTL tuning if the OS is not Linux<li>GTUNE: Add the condition for `bgwriter_lru_maxpages` to be well-adapted with associated workload<li>GTUNE: The parameter `archive_timeout` is from 15 minutes bumped to 30-45 minutes as many current servers don't use the log-shipping method anymore, but streaming and logical replication.<li>GTUNE: Add the configurations of `join_collapse_limit`, `from_collapse_limit`, and `plan_cache_mode`.<li>GTUNE: Rework the self-tuning of `parallel_tuple_cost` configuration<li>GTUNE: Adjust the scale ratio `max_parallel_workers` (vcpu * 1.125 ->> vcpu * 1.25 + 1) and `max_parallel_workers_per_gather` (vcpu / 3 ->> vcpu / 2.5) to have more parallel workers<li>STUNE: Reduce the result of `cpu_tuple_cost` and `parallel_tuple_cost`<li>STUNE: Simplify (reduce) configuration value of `default_statistics_target`<li>STUNE: Simplify (reduce) configuration value of `after_commit_delay` to be workload-based rather than disk-based<li>STUNE: Simplify (increase) configuration value of `bgwriter_delay` (8ms reduction per 1000 IOPS than 10ms)<li>STUNE: Reduce the upper bound of `vacuum_*_min_age` from 25% of associated `vacuum_*_max_age` to 15%<li>STUNE: Stop enforce the option `opt_wal_buffers` to be higher than `PG_PROFILE_OPTMODE.NONE`<li>STUNE: Reduce by half the alignment size of `min_wal_size`, `max_wal_size`, and `wal_keep_size` (The configuration would be better detailed).<li>STUNE: The two parameters `statement_timeout` and `lock_timeout` is reduced significantly.<li>STUNE: A typo in `backend_flsuh_after` has been corrected from 512 MiB to 512 KiB.<li>STUNE: Re-calibrate the algorithm of WAL pre-allocation of zero-filled WAL file (ignore the parameter `wal_init_zero`).</ul><li>Others <ul><li>PY_BKE: The GC has been pushed more with better GC management.<li>PY_WEB: The request's limit has been bumped from 15 reqs per window to 250 reqs (on DEV) and 180 (on PROD)<li>PY_BKE: The initialization on `./src/__init__.py` is improved with better logic. This includes the change in the `./src/utils`, `./src/static` (removed), `./src/tuner/data`, ... modules<li>PY_BKE: The general optimizer has been moved out-of-class to be functional<li>PY_BKE: Add the method :func:`PG_TUNE_ITEM.__repr__()` and remove the argument `output_if_difference_only` in :func:`PG_TUNE_ITEM.out()`/<li>PY_BKE: Enforce the warning when the database has less than 4 GiB of RAM<li>CONF: Remove the scope of :enum:`PGTUNER_SCOPE.KERNEL_BOOT` optimize the boot settings for database<li>CONF: Refactor the enum `PG_SIZING`</ul></ul></div></div></div><div class=accordion-item><h2 class=accordion-header id=hdr000104><button class="accordion-button collapsed" aria-controls=collapse000104 aria-expanded=true data-bs-target=#collapse000104 data-bs-toggle=collapse type=button>v0.1.4 - Expected Date: March 01st 2025</button></h2><div class="accordion-collapse collapse" aria-labelledby=hdr000104 data-bs-parent=#changelogAccordion id=collapse000104><div class=accordion-body><ul><li>Generic <ul><li>Backend: Now input added the `frozen` attribute to indicate whether the parameter expect changes or not.<li>DOC (UI & Backend): Most documentations from the backend and UI are better understanding, helping new developers and users understand what formula is calculated inside.</ul><li>Input Changes <ul><li>The default of parameter `temp_buffers_ratio` is changed from 1/3 (0.33) to 1/4 (0.25)<li>The upper bound of parameter `max_normal_memory_usage` is changed from 0.85 to 0.80<li>The parameters `mem_pool_epsilon_to_rollback` and `mem_pool_tuning_increment` is removed from user input, and hard-coded as 0.0075 and 1/560 in the correction tuning phase.<li>The default parameter of `mem_pool_tuning_ratio` is changed from 0.5 to 0.6<li>The default parameter of `hash_mem_usage_level` is changed from -4 to -6 -> If the PostgreSQL configuration is 2.0, the working memory usage per connection for one arbitrary operation is reduced from 1.1713 to 1.1196)<li>The default parameter `mem_pool_parallel_estimate` is changed from False to True to assume at any time, PostgreSQL can use parallel operation in general, thereby hopefully reduce the working memory per connection for one arbitrary operation by around `vCPU+3` unit of `work_mem * average_ratio`.<li>The upper bound of `wal_segment_size` is reduced from 2 GiB to 128 MiB. The reason of change is added directly from the code `Increase this value is only beneficial when (1) you have a lot of incoming WRITE beyond 16 MiB per transaction, (2) high WAL file rotation time during workload (usually at old kernel and old PostgreSQL version), (3) high archive transfer due to small files (a lot of 16 MiB files) that translated into a mix of random and sequential IOPS, and (4) low number of allowed files in filesystem`<li>Fix the underlying meaning of `min_wal_size`, `max_wal_size`, and `wal_keep_size` in our PostgreSQL understanding by introducing new algorithm that is based on the WAL volume capacity, ensuring checkpoint can be run in a timely manner, during burst workload, and maintained a reasonable number WAL records for streaming replication.<li>Drop the parameter `max_wal_size_remain_upper_size`<li>The lower bound of parameter `autovacuum_utilization_ratio` is changed from 0.50 to 0.30<li>Move the parameter of `num_write_transaction_per_hour_on_workload` from advanced configuration to basic configuration.<li>The default of parameter `num_write_transaction_per_hour_on_workload` is changed from 1M (1 million) to 50K (50 thousand) -> This is translated from 270 attempted WRITE transactions to 13.5 attempted WRITE transactions.<li>Drop the parameter `repurpose_wal_buffers` as it makes zero contribution against small server, unless you having too little RAM and a low-end HDD on the WAL partition.<li>Introduce the parameter `database_size_in_gib` in the basic configuration (default to 10 GiB and maximum at 32 TiB). This is used in the anti-wraparound tuning to be served as the minimum boundary hopefully the data volume can scan randomly at 30% WRITE IOPS on the full data files (not index files). If user don't know the amount of data they would have (for example new on-boarded application), then set to zero value meant a 60% of used volume in the data partition.</ul><li>Algorithm Changes <ul><li>Add small warning if the server is not MINI and available RAM is lower than 4 GiB instead of hard-coded 2 GiB for any profile<li>The parameter `autovacuum_naptime` is now 15 second for one worker and 30 seconds for each additional worker.<li>The autovacuum parameter when INSERT (*_insert_threshold and *_insert_scale_factor) is now share same value as when normal autovacuum.<li>Reduce the `max_wal_size` parameter on general tuning phase.<li>The parameter `archive_timeout` is 15 minutes on large system and 30 to 1 hour on small system in general tuning phase<li>The parameter `checkpoint_timeout` is 30 minutes on MINI profile instead of 15 minutes in general tuning phase<li>The parameter `wal_keep_size` is default to 25 base WAL files (400 MiB as Azure)<li>Introduce the parameter `max_slot_wal_keep_size` (default to -1)<li>Un-necessary workloads are grouped: SEARCH / RAG / GEO --> VECTOR; TSR_HTAP --> HTAP; TSR_OLAP --> OLAP<li>The parameter `default_statistics_target` has minor change.<li>The parameter `checkpoint_flush_after` is backed to 256 KiB at general tuning phase, and bump to 512 KiB and 1 MiB if data volume is strong.<li>Revise failsafe at anti-wraparound tuning<li>Fix the underlying meaning of `min_wal_size`, `max_wal_size`, and `wal_keep_size` in our PostgreSQL understanding by introducing new algorithm that is based on the WAL volume capacity, ensuring checkpoint can be run in a timely manner, during burst workload, and maintained a reasonable number WAL records for streaming replication.<li>The parameter `archive_timeout` is scaled by extra 10 minutes for one unit of larger WAL size (capped at 2 hour)<li>The parameter `checkpoint_timeout` added the minimum time of finishing the checkpoint (at 70 % of mixed data IOPS) depending on the type of workload (workload scale is independent) in the correction tuning phase.<li>The parameter `bgwriter_lru_maxpages` is increased when the disk performance is SSD or stronger.<li>The four parameters `*_flush_after` is added into the correction tuning phase</ul></ul></div></div></div><div class=accordion-item><h2 class=accordion-header id=hdr000103><button class="accordion-button collapsed" aria-controls=collapse000103 aria-expanded=true data-bs-target=#collapse000103 data-bs-toggle=collapse type=button>v0.1.3 (Alpha) - Date: Feb 16th 2025</button></h2><div class="accordion-collapse collapse" aria-labelledby=hdr000103 data-bs-parent=#changelogAccordion id=collapse000103><div class=accordion-body><ul><li>UI & Backend: Remove the "os_reserved_memory" parameter<li>UI: Remove RAID configuration for disk parameters<li>UI & Backend: Add vacuum_safety_level parameter into the tuning guideline<li>UI & Backend: Switch the default disk performance from SSDv1 to SANv1<li>Backend: Update the formula for bgwriter and autovacuum</ul></div></div></div><div class=accordion-item><h2 class=accordion-header id=hdr000102><button class="accordion-button collapsed" aria-controls=collapse000102 aria-expanded=true data-bs-target=#collapse000102 data-bs-toggle=collapse type=button>v0.1.2 (Alpha) - Date: Feb 14th, 2022</button></h2><div class="accordion-collapse collapse" aria-labelledby=hdr000102 data-bs-parent=#changelogAccordion id=collapse000102><div class=accordion-body><ul><li>Cleanup development and legacy code.<li>VACUUM: Add vacuum_failsafe_age and vacuum_multixact_failsafe_age parameter into our tuning guideline. Push two '*_freeze_table_age' parameters into the correction tuning phase. These arguments require good estimation<li>MEMORY: Better performance on memory estimation phase with parallel estimation mode is applied in the correction phase<li>BGWRITER: Adjust the background writer parameters to match its use-case<li>VACUUM: Re-adjust the vacuum threshold and scale factor<li>Tune up some headers and meta tags for better SEO<li>Apply the HTML Jinja2 template for the web page<li>Extend the rate limit window for more requests</ul></div></div></div><div class=accordion-item><h2 class=accordion-header id=hdr000101><button class="accordion-button collapsed" aria-controls=collapse000101 aria-expanded=true data-bs-target=#collapse000101 data-bs-toggle=collapse type=button>v0.1.1 (Alpha) - Date: Feb 09th, 2025</button></h2><div class="accordion-collapse collapse" aria-labelledby=hdr000101 data-bs-parent=#changelogAccordion id=collapse000101><div class=accordion-body><ul><li>Cleanup development and legacy code<li>Better performance on correction tuning phase, especially on the memory pool increase tuning task, fasten from 6ms to 1-2 ms<li>Create robots.txt file for web crawler to index the web page<li>Move `_version` endpoint to the `_health` endpoint with a more dedicated health check; service uptime is reported<li>Refactor the rate-limit middleware: Merge the global rate-limit and the user (IP/Port) rate-limit into one middleware</ul></div></div></div><div class=accordion-item><h2 class=accordion-header id=hdr000100><button class="accordion-button collapsed" aria-controls=collapse000100 aria-expanded=true data-bs-target=#collapse000100 data-bs-toggle=collapse type=button>v0.1.0 (Alpha) - Date: Feb 01st, 2025</button></h2><div class="accordion-collapse collapse" aria-labelledby=hdr000100 data-bs-parent=#changelogAccordion id=collapse000100><div class=accordion-body><ul><li>Initial release of PGTuner<li>Supported for PostgreSQL 13 -> 17</ul></div></div></div></div></section>